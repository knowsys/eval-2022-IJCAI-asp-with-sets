# Evaluation data and software

This repository contains auxiliary resources for the following research work:

[**Simulating Sets in Answer Set Programming**](https://iccl.inf.tu-dresden.de/web/Inproceedings3320/en)
by [Sarah Gaggl](https://iccl.inf.tu-dresden.de/web/Sarah_Gaggl), Philipp Hanisch and [Markus KroÌˆtzsch](https://kbs.inf.tu-dresden.de/mak/). Proceedings of the 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence (IJCAI 2022).

The repository contains two directories with the following contents:
* [eval](eval): Data, logic programs, and our own result measurements for the experiments reported in the paper. The directory contains instructions on how to re-run our experiments.
* [rulewerk](rulewerk): The code of our prototype ASP grounder based on existential rules. The code is a fork of [Rulewerk](https://github.com/knowsys/rulewerk). Instructions on how to use it for the evaluation are given in the `eval` folder.

Feedback or queries are welcome. For contact details, see our homepages linked above.
